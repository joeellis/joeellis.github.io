<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width initial-scale=1"> <title>Streaming Data with Ecto | joeellis.la</title> <meta property="og:title" content="Streaming Data with Ecto"/> <meta name="author" content="Joe Ellis"/> <meta property="og:locale" content="en_US"/> <meta name="description" content="See how to efficiently stream large datasets from a database using Ecto’s Repo.stream."/> <meta property="og:description" content="See how to efficiently stream large datasets from a database using Ecto’s Repo.stream."/> <link rel="canonical" href="http://joeellis.la/streaming-with-ecto/"/> <meta property="og:url" content="http://joeellis.la/streaming-with-ecto/"/> <meta property="og:site_name" content="joeellis.la"/> <meta property="og:type" content="article"/> <meta property="article:published_time" content="2017-05-21T00:00:00-05:00"/> <meta name="twitter:card" content="summary"/> <meta name="twitter:site" content="@notjoellis"/> <meta name="twitter:creator" content="@Joe Ellis"/> <script type="application/ld+json">
{"@context":"http://schema.org","@type":"BlogPosting","headline":"Streaming Data with Ecto","author":{"@type":"Person","name":"Joe Ellis"},"datePublished":"2017-05-21T00:00:00-05:00","dateModified":"2017-05-21T00:00:00-05:00","description":"See how to efficiently stream large datasets from a database using Ecto’s Repo.stream.","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://joeellis.la/assets/img/avatar.png"},"name":"Joe Ellis"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://joeellis.la/streaming-with-ecto/"},"url":"http://joeellis.la/streaming-with-ecto/"}</script> <link rel="stylesheet" href="/css/main.css"> <link rel="alternate" type="application/atom+xml" title="joeellis.la" href="http://joeellis.la/feed.xml"/> <link rel="canonical" href="http://joeellis.la/streaming-with-ecto/"> <meta content="See how to efficiently stream large datasets from a database using Ecto's Repo.stream." property="description"> <meta property="og:image" content="http://joeellis.la/assets/img/avatar.png"> <meta property="article:tag" content="elixir"> <meta property="article:tag" content="ecto"> <meta name="twitter:title" content="Streaming Data with Ecto"> <meta name="twitter:description" content="See how to efficiently stream large datasets from a database using Ecto's Repo.stream."> <meta name="twitter:image" content="http://joeellis.la/assets/img/avatar.png"> </head> <body> <div class="header-container"> <nav class="site-nav"> <div class="trigger"> <a class="page-link" href="/about/">About</a> <a class="page-link" href="/feed.xml">RSS</a> </div> </nav> </div> <div class="wrapper"> <div class="page-content"> <div class="header-intro"> <div class="intro-details"> <div class="intro-photo"> <a href="http://joeellis.la"> <img class="avatar-photo" src="/assets/images/avatar.png" width="55" height="55"/> </a> </div> <p class="intro-description"> <a href="http://joeellis.la">My name is Joe Ellis and I am a full stack developer in New Orleans, interested all things Elixir, Ruby, and Javascript.</a> </p> </div> </div> <hr/> <div class="post"> <header class="post-header"> <h1 class="post-title">Streaming Data with Ecto</h1> <p class="post-meta">May 21, 2017</p> </header> <article class="post-content"> <p><strong>Note</strong>: if you are not familiar with Elixir streams, you should <a href="http://elixir-lang.org/getting-started/enumerables-and-streams.html#streams">read the documentation</a> on streams first or this post may be hard to follow.</p> <p>It’s a given that in your programming career, you will need to fetch a dataset and run some set of operations on it. With small datasets, you can often get away with fetching the records at once and doing what you need to do. But if you’re trying to fetch a large dataset, you will run into some common problems. It’s <strong>very</strong> slow, creates a blocking database connection, and most database libraries will load the dataset into memory which can slow down or kill your server.</p> <p>Fortunately, Ecto <a href="https://hexdocs.pm/ecto/Ecto.Repo.html#c:stream/2">has a fantastic tool</a> for handling this situation, <a href="https://hexdocs.pm/ecto/Ecto.Repo.html#c:stream/2"><code class="highlighter-rouge">Repo.stream/2</code></a>. <code class="highlighter-rouge">Repo.stream/2</code> avoids fetching everything at once and instead fetches data in iterative cycles, performing operations on each record along the way.</p> <p>In this example, we will work through a typical app feature: exporting database records as CSV files. It’s a useful feature and is a good example to show how versatile Elixir streams can be.</p> <p>First, let’s look at some code:</p> <figure class="highlight"><pre><code class="language-elixir" data-lang="elixir"><span class="k">defmodule</span> <span class="no">UserExporter</span> <span class="k">do</span>
  <span class="nv">@columns</span> <span class="err">~</span><span class="n">w</span><span class="p">(</span> <span class="n">id</span> <span class="n">email</span> <span class="n">inserted_at</span> <span class="n">updated_at</span> <span class="p">)</span><span class="n">a</span>

  <span class="k">def</span> <span class="n">export</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="k">do</span>
    <span class="n">path</span> <span class="o">=</span> <span class="sd">"</span><span class="s2">/tmp/users.csv"</span>

    <span class="no">Repo</span><span class="o">.</span><span class="n">transaction</span> <span class="k">fn</span> <span class="o">-&gt;</span>
      <span class="n">query</span>
      <span class="o">|&gt;</span> <span class="no">Repo</span><span class="o">.</span><span class="n">stream</span>
      <span class="o">|&gt;</span> <span class="no">Stream</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">&amp;</span><span class="n">parse_line</span><span class="o">/</span><span class="m">1</span><span class="p">)</span>
      <span class="o">|&gt;</span> <span class="no">CSV</span><span class="o">.</span><span class="n">encode</span>
      <span class="o">|&gt;</span> <span class="no">Enum</span><span class="o">.</span><span class="n">into</span><span class="p">(</span><span class="no">File</span><span class="o">.</span><span class="n">stream!</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="p">[</span><span class="ss">:write</span><span class="p">,</span> <span class="ss">:utf8</span><span class="p">]))</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="k">defp</span> <span class="n">parse_line</span><span class="p">(</span><span class="n">user</span><span class="p">)</span> <span class="k">do</span>
    <span class="c1"># order our data to match our column order</span>
    <span class="no">Enum</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nv">@columns</span><span class="p">,</span> <span class="o">&amp;</span><span class="no">Map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">user</span><span class="p">,</span> <span class="nv">&amp;1</span><span class="p">))</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure> <p>Here we have a module with one public function, <code class="highlighter-rouge">export/1</code>, that accepts an Ecto query and returns back a file stream.</p> <p>At the top, we declare a <code class="highlighter-rouge">@columns</code> module attribute to define the user data to show in our file. We’ll need to refer to this <code class="highlighter-rouge">@columns</code> list later to reorder our data for the CSV file.</p> <p>Next is the meat of the exporter. The first thing we do is open up a database transaction. This is a good idea when iterating over a large dataset and also a requirement when using <code class="highlighter-rouge">Repo.stream/2</code> with either a MySQL or Postgres. All work using <code class="highlighter-rouge">Repo.stream/2</code> needs to take place inside a transaction.</p> <p>Having opened a transaction, we pass our query to <code class="highlighter-rouge">Repo.stream/2</code> which creates the initial stream. Remember, this only creates the stream; streams are lazily evaluated, so we haven’t starting making any calls to the database yet.</p> <p>We then pass the stream to a <code class="highlighter-rouge">Stream.map</code> function which will fetch and transform data from each user struct into a list of user data matching the order of our columns.</p> <p>Using the wonderful <a href="https://github.com/beatrichartz/csv">CSV library</a>, we then pass the stream to the <code class="highlighter-rouge">CSV.encode/1</code> function to do all the hard work. <code class="highlighter-rouge">CSV.encode/1</code> both accepts and return streams, so it fits right into our pipeline setup here.</p> <p>Finally, a call to <code class="highlighter-rouge">Enum.into</code> runs the whole stream, and the actual database calls start. By default, <code class="highlighter-rouge">Repo.stream/2</code> pulls down 500 records at a time, and each is parsed and written to a file at <code class="highlighter-rouge">tmp/users.csv</code>. Lastly, our function returns a file stream that points to our newly created file. We can use this new stream to do more file-based operations or start some other stream-based work, like uploading the file to S3, etc.</p> <p>As a test, we can see the results of our CSV in an iex console:</p> <figure class="highlight"><pre><code class="language-elixir" data-lang="elixir"><span class="n">iex</span><span class="o">&gt;</span> <span class="p">{</span><span class="ss">:ok</span><span class="p">,</span> <span class="n">file</span><span class="p">}</span> <span class="o">=</span> <span class="no">UserExporter</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">from</span> <span class="n">u</span> <span class="ow">in</span> <span class="no">User</span><span class="p">)</span>
<span class="p">{</span><span class="ss">:ok</span><span class="p">,</span>
 <span class="p">%</span><span class="no">File</span><span class="o">.</span><span class="no">Stream</span><span class="p">{</span><span class="ss">line_or_bytes:</span> <span class="ss">:line</span><span class="p">,</span>
  <span class="ss">modes:</span> <span class="p">[</span><span class="ss">:write</span><span class="p">,</span> <span class="p">{</span><span class="ss">:encoding</span><span class="p">,</span> <span class="ss">:utf8</span><span class="p">},</span> <span class="ss">:binary</span><span class="p">],</span> <span class="ss">path:</span> <span class="sd">"</span><span class="s2">/tmp/users.csv"</span><span class="p">,</span>
  <span class="ss">raw:</span> <span class="no">false</span><span class="p">}}</span>
<span class="n">iex</span><span class="o">&gt;</span> <span class="no">File</span><span class="o">.</span><span class="n">read!</span><span class="p">(</span><span class="n">file</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
<span class="c1">#=&gt; "1,joe@example.com,2017-04-27 21:57:42.972524,2017-05-20 18:48:16.235083\r\n2,jane@example.com,2017-04-27 18:36:32.053556,2017-04-27 18:36:32.065434\r\n3,jill@example.com,2017-04-27 18:37:43.503567,2017-04-27 18:37:43.503575\r\n"</span></code></pre></figure> <p>Pretty neat, eh? Using streams, we created a simple and ordered pipeline to efficiently fetch data, transform it, and write it into a file - 500 records at a time. <code class="highlighter-rouge">Repo.stream/2</code> is a very handy tool dealing with large datasets, I highly recommend you give it a try if you haven’t heard of it before.</p> </article> <hr> <div class="question"> <a class="twitter-follow-button" href="https://twitter.com/notjoeellis" data-show-count="true" data-size="large"> Follow @notjoeellis </a> <script type="text/javascript">window.twttr=function(t,e,r){var n,i,w=t.getElementsByTagName(e)[0];if(!t.getElementById(r))return i=t.createElement(e),i.id=r,i.src="https://platform.twitter.com/widgets.js",w.parentNode.insertBefore(i,w),window.twttr||(n={_e:[],ready:function(t){n._e.push(t)}})}(document,"script","twitter-wjs");</script> </div> </div> </div> <footer class="site-footer"> <p class="small">joeellis.la &copy; 2017</p> </footer> </div> </body> <script>!function(e,t,a,n,c,s,o){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,s=t.createElement(a),o=t.getElementsByTagName(a)[0],s.async=1,s.src=n,o.parentNode.insertBefore(s,o)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-99074897-1","auto"),ga("send","pageview");</script> </html>